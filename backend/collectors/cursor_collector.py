import requests
import json
from datetime import datetime
from typing import List, Dict, Optional
from bs4 import BeautifulSoup
import re
import time
from .base import BaseCollector, CollectorItem
from config import settings
from websocket_manager import ProgressReporter


class CursorCollector(BaseCollector):
    """Cursor IDE æ›´æ–°æ—¥å¿—é‡‡é›†å™¨"""

    def __init__(self):
        super().__init__()
        self.name = "cursor_collector"
        self.description = "Cursor IDE æ›´æ–°æ—¥å¿—é‡‡é›†å™¨"
        self.url = "https://cursor.com/changelog"
        self.progress_reporter = ProgressReporter("cursor_collection")
        self.db_session = None  # æ•°æ®åº“ä¼šè¯ï¼Œç”±è·¯ç”±è®¾ç½®

    def _print_progress(
        self, current: int, total: int, message: str, extra_info: str = ""
    ):
        """æ‰“å°è¿›åº¦æ¡"""
        percentage = (current / total) * 100 if total > 0 else 0
        bar_length = 20
        filled_length = int(bar_length * current // total) if total > 0 else 0
        bar = "â–ˆ" * filled_length + "â–‘" * (bar_length - filled_length)
        print(
            f"ğŸ“Š [{bar}] {percentage:.1f}% ({current}/{total}) {message} {extra_info}"
        )

    async def collect(self) -> List[CollectorItem]:
        """
        é‡‡é›† Cursor æ›´æ–°æ—¥å¿—
        """
        try:
            # å‘é€å¼€å§‹çŠ¶æ€
            await self.progress_reporter.report_status(
                "started", "å¼€å§‹é‡‡é›† Cursor æ›´æ–°æ—¥å¿—..."
            )

            print("ğŸ”„ å¼€å§‹é‡‡é›† cursor_collector æ›´æ–°æ—¥å¿—...")
            start_time = time.time()

            # é‡‡é›†ä¿¡æ¯ç»Ÿè®¡
            collection_info = {
                "total_versions": 0,
                "new_versions": 0,
                "existing_versions": 0,
                "api_calls_made": 0,
                "processing_details": [],
                "total_time": 0,
            }

            # æ­¥éª¤1: è·å–ç½‘é¡µæ•°æ®
            await self.progress_reporter.report_status(
                "processing", "æ­£åœ¨è·å– Cursor ç½‘ç«™æ•°æ®..."
            )

            print("ğŸ“¥ æ­£åœ¨è·å– Cursor ç½‘ç«™æ•°æ®...")
            response = requests.get(self.url, timeout=10)
            response.raise_for_status()
            print("âœ… æˆåŠŸè·å–ç½‘ç«™æ•°æ®")

            # æ­¥éª¤2: è§£æHTML
            await self.progress_reporter.report_status(
                "processing", "æ­£åœ¨è§£æHTMLé¡µé¢..."
            )

            print("ğŸ” æ­£åœ¨è§£æHTMLé¡µé¢...")
            soup = BeautifulSoup(response.text, "html.parser")
            versions = self._parse_versions(soup)
            collection_info["total_versions"] = len(versions)

            # å‘é€è§£æå®ŒæˆçŠ¶æ€
            await self.progress_reporter.report_status(
                "processing",
                f"è§£æå®Œæˆï¼Œæ‰¾åˆ° {len(versions)} ä¸ªç‰ˆæœ¬",
                {"versions_found": len(versions)},
            )

            print(f"ğŸ“‹ æ‰¾åˆ° {len(versions)} ä¸ªç‰ˆæœ¬ï¼Œå¼€å§‹å¤„ç†...")

            if not versions:
                await self.progress_reporter.report_status(
                    "completed", "æœªæ‰¾åˆ°ä»»ä½•ç‰ˆæœ¬ï¼Œé‡‡é›†å®Œæˆ"
                )
                return []

            # æ­¥éª¤3: å¤„ç†ç‰ˆæœ¬æ•°æ®
            await self.progress_reporter.report_status(
                "processing", "å¼€å§‹å¤„ç†ç‰ˆæœ¬æ•°æ®..."
            )

            print(f"\nğŸ”„ å¼€å§‹å¤„ç†ç‰ˆæœ¬æ•°æ®...")
            results = []

            for i, version in enumerate(versions):
                version_start_time = time.time()
                current_progress = i + 1

                # å‘é€è¿›åº¦æ›´æ–°
                await self.progress_reporter.report_progress(
                    current_progress,
                    len(versions),
                    f"å¤„ç†ç‰ˆæœ¬ {version['version']}",
                    {
                        "version": version["version"],
                        "release_date": version["release_date"],
                        "title": (
                            version["title"][:100] + "..."
                            if len(version["title"]) > 100
                            else version["title"]
                        ),
                    },
                )

                # æ‰“å°è¿›åº¦
                self._print_progress(
                    current_progress,
                    len(versions),
                    f"å¤„ç†ç‰ˆæœ¬ {version['version']}",
                    f"â±ï¸ å·²ç”¨æ—¶ {time.time() - start_time:.1f}s",
                )

                # æ£€æŸ¥ç‰ˆæœ¬æ˜¯å¦å·²å­˜åœ¨
                existing = self._check_existing_version(version["version"])
                if existing:
                    # ç‰ˆæœ¬å·²å­˜åœ¨ï¼Œè·³è¿‡APIè°ƒç”¨
                    await self.progress_reporter.report_version_progress(
                        version["version"],
                        "skipped",
                        f"ç‰ˆæœ¬ {version['version']} å·²å­˜åœ¨ï¼Œè·³è¿‡APIè°ƒç”¨",
                        api_calls=0,
                        processing_time=time.time() - version_start_time,
                    )

                    print(f"ğŸ“‹ ç‰ˆæœ¬ {version['version']} å·²å­˜åœ¨ï¼Œè·³è¿‡APIè°ƒç”¨")
                    collection_info["existing_versions"] += 1

                    collection_info["processing_details"].append(
                        {
                            "version": version["version"],
                            "status": "existing",
                            "message": f"ç‰ˆæœ¬ {version['version']} å·²å­˜åœ¨ï¼Œè·³è¿‡APIè°ƒç”¨",
                            "api_calls": 0,
                            "processing_time": time.time() - version_start_time,
                        }
                    )

                    # åˆ›å»º CollectorItemï¼ˆä»æ•°æ®åº“è·å–ï¼‰
                    if existing:
                        item = CollectorItem(
                            title=f"{version['title']} ({existing.translated_title})",
                            summary=f"Cursor {version['version']} æ›´æ–°",
                            content=existing.original_content,
                            url=existing.url,
                            source="Cursor",
                            published_at=existing.release_date,
                            tags=["cursor", "ide", "update"],
                            extra_data={
                                "version": existing.version,
                                "release_date": existing.release_date.isoformat(),
                                "original_title": version["title"],
                                "translated_title": existing.translated_title,
                                "original_content": existing.original_content,
                                "translated_content": existing.translated_content,
                                "analysis": existing.analysis,
                                "is_major": existing.is_major,
                                "collection_status": "existing",
                            },
                        )
                        results.append(item)
                        continue

                # ğŸ’° åªæœ‰æ–°ç‰ˆæœ¬æ‰ä¼šè°ƒç”¨API
                await self.progress_reporter.report_version_progress(
                    version["version"],
                    "processing",
                    f"æ–°ç‰ˆæœ¬ {version['version']}ï¼Œå¼€å§‹APIè°ƒç”¨...",
                )

                print(f"\nğŸ†• æ–°ç‰ˆæœ¬ {version['version']}ï¼Œå¼€å§‹APIè°ƒç”¨...")
                collection_info["new_versions"] += 1
                collection_info["api_calls_made"] += 1  # ç°åœ¨åªéœ€è¦1æ¬¡APIè°ƒç”¨

                # APIè°ƒç”¨è¿›åº¦æ˜¾ç¤º
                api_start_time = time.time()

                # ä¸€æ¬¡æ€§å®Œæˆç¿»è¯‘å’Œåˆ†æ
                await self.progress_reporter.report_status(
                    "processing", f"æ­£åœ¨è¿›è¡ŒAIç¿»è¯‘å’Œåˆ†æ - ç‰ˆæœ¬ {version['version']}"
                )

                print(f"   ğŸ”„ [1/1] æ­£åœ¨è¿›è¡ŒAIç¿»è¯‘å’Œåˆ†æ...")
                api_result = self._translate_and_analyze_with_deepseek(
                    version["title"], version["content"]
                )
                print(
                    f"   âœ… [1/1] AIç¿»è¯‘å’Œåˆ†æå®Œæˆ (ç”¨æ—¶ {time.time() - api_start_time:.1f}s)"
                )

                total_api_time = time.time() - api_start_time
                print(
                    f"   ğŸ‰ ç‰ˆæœ¬ {version['version']} APIè°ƒç”¨å®Œæˆ (æ€»ç”¨æ—¶ {total_api_time:.1f}s)"
                )

                # å‘é€ç‰ˆæœ¬å®ŒæˆçŠ¶æ€
                await self.progress_reporter.report_version_progress(
                    version["version"],
                    "completed",
                    f"ç‰ˆæœ¬ {version['version']} å¤„ç†å®Œæˆ",
                    api_calls=1,
                    processing_time=time.time() - version_start_time,
                )

                # è§£æAPIè¿”å›ç»“æœ
                translated_title = api_result.get("translated_title", "ç¿»è¯‘å¤±è´¥")
                translated_content = api_result.get("translated_content", "ç¿»è¯‘å¤±è´¥")
                analysis = api_result.get("analysis", "åˆ†æå¤±è´¥")

                collection_info["processing_details"].append(
                    {
                        "version": version["version"],
                        "status": "new",
                        "message": f"æ–°ç‰ˆæœ¬ {version['version']}ï¼Œå·²å®ŒæˆAPIè°ƒç”¨",
                        "api_calls": 1,  # ç°åœ¨åªéœ€è¦1æ¬¡
                        "processing_time": time.time() - version_start_time,
                        "api_time": total_api_time,
                    }
                )

                # åˆ›å»º CollectorItem
                item = CollectorItem(
                    title=f"{version['title']} ({translated_title})",
                    summary=f"Cursor {version['version']} æ›´æ–°",
                    content=version["content"],
                    url=self.url + f"#{version['version']}",
                    source="Cursor",
                    published_at=datetime.fromisoformat(version["release_date"]),
                    tags=["cursor", "ide", "update"],
                    extra_data={
                        "version": version["version"],
                        "release_date": version["release_date"],
                        "original_title": version["title"],
                        "translated_title": translated_title,
                        "original_content": version["content"],
                        "translated_content": translated_content,
                        "analysis": analysis,
                        "is_major": version["version"].count(".")
                        == 1,  # ä¸»ç‰ˆæœ¬å¦‚ 1.0, 1.1
                        "collection_status": "new",
                    },
                )

                results.append(item)

            # æœ€ç»ˆè¿›åº¦æ˜¾ç¤º
            await self.progress_reporter.report_progress(
                len(versions), len(versions), "æ‰€æœ‰ç‰ˆæœ¬å¤„ç†å®Œæˆ"
            )

            self._print_progress(
                len(versions),
                len(versions),
                "å¤„ç†å®Œæˆ",
                f"â±ï¸ æ€»ç”¨æ—¶ {time.time() - start_time:.1f}s",
            )

            # æ±‡æ€»ç»Ÿè®¡
            total_time = time.time() - start_time
            collection_info["total_time"] = total_time

            # å‘é€æœ€ç»ˆç»Ÿè®¡
            await self.progress_reporter.report_stats(
                {
                    "total_versions": collection_info["total_versions"],
                    "new_versions": collection_info["new_versions"],
                    "existing_versions": collection_info["existing_versions"],
                    "api_calls_made": collection_info["api_calls_made"],
                    "total_time": total_time,
                }
            )

            # å‘é€å®ŒæˆçŠ¶æ€
            await self.progress_reporter.report_status(
                "completed",
                f"é‡‡é›†å®Œæˆï¼å…±å¤„ç† {collection_info['total_versions']} ä¸ªç‰ˆæœ¬",
                collection_info,
            )

            print(f"\nğŸ‰ é‡‡é›†å®Œæˆï¼")
            print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
            print(f"   ğŸ“‹ æ€»ç‰ˆæœ¬æ•°: {collection_info['total_versions']}")
            print(f"   ğŸ†• æ–°ç‰ˆæœ¬æ•°: {collection_info['new_versions']}")
            print(f"   ğŸ“š å·²å­˜åœ¨ç‰ˆæœ¬: {collection_info['existing_versions']}")
            print(f"   ğŸ’° APIè°ƒç”¨æ¬¡æ•°: {collection_info['api_calls_made']}")
            print(f"   â±ï¸ æ€»ç”¨æ—¶: {total_time:.1f}s")
            if collection_info["new_versions"] > 0:
                avg_time = total_time / collection_info["new_versions"]
                print(f"   ğŸ“ˆ å¹³å‡æ¯ä¸ªæ–°ç‰ˆæœ¬ç”¨æ—¶: {avg_time:.1f}s")

            # å°†é‡‡é›†ä¿¡æ¯å­˜å‚¨åˆ°ç»“æœä¸­
            if results:
                results[0].extra_data["collection_info"] = collection_info

            return results

        except Exception as e:
            # å‘é€é”™è¯¯çŠ¶æ€
            await self.progress_reporter.report_status(
                "error", f"é‡‡é›† Cursor æ›´æ–°æ—¥å¿—å¤±è´¥: {str(e)}"
            )

            print(f"\nâŒ é‡‡é›† Cursor æ›´æ–°æ—¥å¿—å¤±è´¥: {e}")
            return []

    def _check_existing_version(self, version: str):
        """æ£€æŸ¥ç‰ˆæœ¬æ˜¯å¦å·²å­˜åœ¨äºæ•°æ®åº“ä¸­"""
        if not self.db_session:
            return None

        try:
            from models import CursorUpdate

            existing = (
                self.db_session.query(CursorUpdate)
                .filter(CursorUpdate.version == version)
                .first()
            )
            return existing
        except Exception as e:
            print(f"æ£€æŸ¥ç‰ˆæœ¬æ—¶å‡ºé”™: {e}")
            return None

    def _parse_versions(self, soup: BeautifulSoup) -> List[Dict]:
        """è§£æç‰ˆæœ¬ä¿¡æ¯ - åŸºäºå®é™…é¡µé¢ç»“æ„ä¼˜åŒ–"""
        versions = []

        try:
            print("ğŸ” å¼€å§‹è§£æHTMLé¡µé¢...")

            # åŸºäºå®é™…é¡µé¢ç»“æ„çš„è§£æç­–ç•¥
            print("   ğŸ”„ æŸ¥æ‰¾ç‰ˆæœ¬ä¿¡æ¯...")

            # 1. æŸ¥æ‰¾æ‰€æœ‰æ—¥æœŸ
            page_text = soup.get_text()
            date_pattern = re.compile(r"([A-Za-z]+ \d+, \d{4})")
            dates = date_pattern.findall(page_text)
            print(f"   ğŸ“… æ‰¾åˆ° {len(dates)} ä¸ªæ—¥æœŸ: {dates}")

            # 2. æ™ºèƒ½ç‰ˆæœ¬å·æŸ¥æ‰¾ - å¤šç­–ç•¥ç»„åˆ
            valid_versions = []

            # ç­–ç•¥1: æŸ¥æ‰¾é¡µé¢ä¸­æ˜ç¡®æ ‡è®°çš„ç‰ˆæœ¬å·ï¼ˆæ–‡æœ¬å†…å®¹ï¼‰
            version_elements = soup.find_all(string=re.compile(r"^\d+\.\d+$"))
            for element in version_elements:
                version = element.strip()
                if version and re.match(r"^\d+\.\d+$", version):
                    if self._is_valid_cursor_version(version):
                        valid_versions.append(version)

            # ç­–ç•¥2: æ™ºèƒ½å…ƒç´ æœç´¢ - åŸºäºè¯­ä¹‰è€Œéç‰¹å®šæ ‡ç­¾
            # æŸ¥æ‰¾å¯èƒ½åŒ…å«ç‰ˆæœ¬å·çš„å…ƒç´ ï¼ˆä¸é™äºpæ ‡ç­¾ï¼‰
            potential_version_elements = soup.find_all(
                lambda tag: tag.name in ["p", "span", "div", "h1", "h2", "h3", "strong"]
                and tag.get_text().strip()
                and re.match(r"^\d+\.\d+$", tag.get_text().strip())
            )

            for element in potential_version_elements:
                version = element.get_text().strip()
                if self._is_valid_cursor_version(version):
                    # éªŒè¯ä¸Šä¸‹æ–‡ - ç¡®ä¿æ˜¯ç‰ˆæœ¬å·è€Œéå…¶ä»–æ•°å­—
                    if self._validate_version_context(element):
                        valid_versions.append(version)

            # ç­–ç•¥3: CSSé€‰æ‹©å™¨æœç´¢ - é’ˆå¯¹å¸¸è§çš„ç‰ˆæœ¬å·å®¹å™¨
            version_selectors = [
                # å¸¸è§çš„ç‰ˆæœ¬å·å®¹å™¨æ¨¡å¼
                '[class*="version"]',
                '[class*="tag"]',
                '[class*="badge"]',
                '[class*="label"]',
                # åŸºäºæ‚¨æä¾›çš„HTMLç»“æ„
                'div[class*="flex"] p',
                'div[class*="items-center"] p',
                # é€šç”¨çš„å¯èƒ½åŒ…å«ç‰ˆæœ¬å·çš„å…ƒç´ 
                'p:not([class*="text-"]):not([class*="description"])',
            ]

            for selector in version_selectors:
                try:
                    elements = soup.select(selector)
                    for element in elements:
                        text = element.get_text().strip()
                        if re.match(
                            r"^\d+\.\d+$", text
                        ) and self._is_valid_cursor_version(text):
                            valid_versions.append(text)
                except Exception:
                    continue

            # ç­–ç•¥4: å¦‚æœä»¥ä¸Šæ–¹æ³•æ‰¾åˆ°çš„ç‰ˆæœ¬ä¸å¤Ÿï¼Œä½¿ç”¨æ–‡æœ¬æ¨¡å¼åŒ¹é…
            if len(valid_versions) < 3:
                print("   ğŸ”„ ä½¿ç”¨æ–‡æœ¬æ¨¡å¼åŒ¹é…ç­–ç•¥...")
                version_pattern = re.compile(r"\b(\d+\.\d+)\b")
                version_matches = version_pattern.findall(page_text)

                for version in version_matches:
                    if self._is_valid_cursor_version(version):
                        valid_versions.append(version)

            # å»é‡å¹¶æŒ‰ç‰ˆæœ¬å·æ’åº
            unique_versions = list(set(valid_versions))
            unique_versions.sort(
                key=lambda x: [int(v) for v in x.split(".")], reverse=True
            )

            # æ™ºèƒ½è¿‡æ»¤ï¼šä¼˜å…ˆé€‰æ‹©å·²çŸ¥ç‰ˆæœ¬ï¼ŒåŒæ—¶æ”¯æŒæ–°ç‰ˆæœ¬
            filtered_versions = self._filter_cursor_versions(unique_versions)

            # é™åˆ¶ç‰ˆæœ¬æ•°é‡ï¼Œå–å‰6ä¸ªæœ€æ–°ç‰ˆæœ¬
            unique_versions = filtered_versions[:6]

            print(f"   ğŸ”¢ æ‰¾åˆ° {len(unique_versions)} ä¸ªç‰ˆæœ¬å·: {unique_versions}")

            # 3. æŸ¥æ‰¾æ‰€æœ‰h2æ ‡ç­¾ï¼ˆç‰ˆæœ¬æ ‡é¢˜ï¼‰
            h2_headers = soup.find_all("h2")
            version_titles = []
            for h2 in h2_headers:
                title = h2.get_text().strip()
                if title.lower() != "changelog":  # è·³è¿‡ä¸»æ ‡é¢˜
                    version_titles.append(title)

            print(f"   ğŸ“„ æ‰¾åˆ° {len(version_titles)} ä¸ªç‰ˆæœ¬æ ‡é¢˜")

            # 4. å°†ç‰ˆæœ¬å·ã€æ—¥æœŸå’Œæ ‡é¢˜é…å¯¹
            version_info_pairs = []

            # ç¡®ä¿æˆ‘ä»¬æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥é…å¯¹
            min_count = min(len(unique_versions), len(dates), len(version_titles))

            for i in range(min_count):
                version_info_pairs.append(
                    (unique_versions[i], dates[i], version_titles[i])
                )

            # å¦‚æœè¿˜æœ‰å‰©ä½™çš„ç‰ˆæœ¬å·ï¼Œä½¿ç”¨ä¼°ç®—çš„æ•°æ®
            if len(unique_versions) > min_count:
                for i in range(min_count, len(unique_versions)):
                    version_info_pairs.append(
                        (
                            unique_versions[i],
                            (
                                dates[0] if dates else "January 1, 2025"
                            ),  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ—¥æœŸæˆ–é»˜è®¤æ—¥æœŸ
                            f"Cursor {unique_versions[i]} Update",
                        )
                    )

            print(f"   ğŸ“‹ åˆ›å»ºäº† {len(version_info_pairs)} ä¸ªç‰ˆæœ¬ä¿¡æ¯å¯¹")

            # 5. ä¸ºæ¯ä¸ªç‰ˆæœ¬åˆ›å»ºè¯¦ç»†ä¿¡æ¯
            for i, (version_num, date, title) in enumerate(version_info_pairs):
                try:
                    print(f"   ğŸ”„ å¤„ç†ç‰ˆæœ¬ {version_num}: {title[:50]}...")

                    # æŸ¥æ‰¾ç‰ˆæœ¬ç›¸å…³çš„å†…å®¹
                    content = self._find_version_content_by_title(soup, title)

                    # è§£æå‘å¸ƒæ—¥æœŸ
                    release_date = self._parse_date(date)

                    version_info = {
                        "version": version_num,
                        "release_date": release_date,
                        "title": title,
                        "content": content,
                    }

                    versions.append(version_info)
                    print(f"   âœ… ç‰ˆæœ¬ {version_num} å¤„ç†æˆåŠŸ")

                except Exception as e:
                    print(f"   âŒ ç‰ˆæœ¬ {version_num} å¤„ç†å¤±è´¥: {e}")
                    continue

            print(f"   âœ… æˆåŠŸè§£æ {len(versions)} ä¸ªç‰ˆæœ¬")

            # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®
            if not versions:
                print("   âš ï¸ è§£æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®...")
                versions = self._get_fallback_versions()

            return versions

        except Exception as e:
            print(f"   âŒ è§£æHTMLå¤±è´¥: {e}")
            print("   ğŸ”„ ä½¿ç”¨å¤‡ç”¨æ•°æ®")
            return self._get_fallback_versions()

    def _find_version_content_by_title(self, soup: BeautifulSoup, title: str) -> str:
        """æ ¹æ®æ ‡é¢˜æŸ¥æ‰¾ç‰ˆæœ¬ç›¸å…³çš„å†…å®¹"""
        try:
            content_parts = []

            # æŸ¥æ‰¾æ ‡é¢˜å¯¹åº”çš„h2å…ƒç´ 
            h2_element = soup.find("h2", string=title)
            if not h2_element:
                # å°è¯•æ¨¡ç³ŠåŒ¹é…
                h2_elements = soup.find_all("h2")
                for h2 in h2_elements:
                    if title in h2.get_text():
                        h2_element = h2
                        break

            if h2_element:
                # æŸ¥æ‰¾è¯¥h2å…ƒç´ åé¢çš„å†…å®¹
                current = h2_element

                # å‘åæŸ¥æ‰¾å…„å¼Ÿå…ƒç´ 
                for sibling in current.find_next_siblings():
                    # å¦‚æœé‡åˆ°ä¸‹ä¸€ä¸ªh2ï¼Œåœæ­¢
                    if sibling.name == "h2":
                        break

                    # æ”¶é›†h3æ ‡ç­¾å†…å®¹
                    if sibling.name == "h3":
                        h3_text = sibling.get_text().strip()
                        if h3_text and len(h3_text) > 3:
                            content_parts.append(h3_text)

                    # æ”¶é›†æ®µè½å†…å®¹
                    elif sibling.name == "p":
                        p_text = sibling.get_text().strip()
                        if p_text and len(p_text) > 10:
                            content_parts.append(p_text)

                    # æ”¶é›†divå†…å®¹
                    elif sibling.name == "div":
                        div_text = sibling.get_text().strip()
                        if div_text and len(div_text) > 10:
                            # æŸ¥æ‰¾åŠŸèƒ½ç›¸å…³çš„å†…å®¹
                            if any(
                                keyword in div_text.lower()
                                for keyword in [
                                    "agent",
                                    "planning",
                                    "context",
                                    "tab",
                                    "memory",
                                    "search",
                                    "improvement",
                                    "feature",
                                    "better",
                                    "faster",
                                    "new",
                                    "background",
                                    "slack",
                                    "to-do",
                                    "todo",
                                    "queued",
                                    "messages",
                                    "pr",
                                    "indexing",
                                    "embeddings",
                                    "semantic",
                                    "merge",
                                    "conflicts",
                                    "bugbot",
                                    "mcp",
                                    "pricing",
                                    "rules",
                                    "terminal",
                                    "images",
                                ]
                            ):
                                content_parts.append(div_text)

                    # é™åˆ¶å†…å®¹æ•°é‡
                    if len(content_parts) >= 10:
                        break

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¶³å¤Ÿå†…å®¹ï¼Œå°è¯•é€šç”¨æœç´¢
            if len(content_parts) < 3:
                # æœç´¢åŒ…å«æ ‡é¢˜å…³é”®è¯çš„å†…å®¹
                title_keywords = title.lower().split()
                all_elements = soup.find_all(["h3", "p", "div"])

                for element in all_elements:
                    text = element.get_text().strip()
                    if len(text) > 10:
                        # å¦‚æœæ–‡æœ¬åŒ…å«æ ‡é¢˜ä¸­çš„å…³é”®è¯
                        if any(keyword in text.lower() for keyword in title_keywords):
                            content_parts.append(text)
                            if len(content_parts) >= 8:
                                break

            # è¿”å›å†…å®¹
            if content_parts:
                return "\n".join(content_parts[:8])  # è¿”å›å‰8ä¸ªå†…å®¹
            else:
                return f"New features and improvements: {title}"

        except Exception as e:
            print(f"   âŒ æŸ¥æ‰¾å†…å®¹å¤±è´¥: {e}")
            return f"New features and improvements: {title}"

    def _find_version_title(self, soup: BeautifulSoup, version: str) -> str:
        """æŸ¥æ‰¾ç‰ˆæœ¬çš„ä¸»è¦æ ‡é¢˜"""
        try:
            # æŸ¥æ‰¾h1, h2æ ‡ç­¾ä¸­çš„ä¸»è¦åŠŸèƒ½æ ‡é¢˜
            major_headers = soup.find_all(["h1", "h2"])

            for header in major_headers:
                header_text = header.get_text().strip()

                # è·³è¿‡é¡µé¢æ ‡é¢˜
                if header_text.lower() in ["changelog", "cursor changelog"]:
                    continue

                # æŸ¥æ‰¾æœ‰æ„ä¹‰çš„åŠŸèƒ½æ ‡é¢˜
                if len(header_text) > 10 and any(
                    keyword in header_text.lower()
                    for keyword in [
                        "agent",
                        "planning",
                        "context",
                        "tab",
                        "better",
                        "faster",
                        "background",
                        "slack",
                        "improvement",
                        "feature",
                        "new",
                        "update",
                    ]
                ):
                    return header_text

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›é»˜è®¤æ ‡é¢˜
            return f"Cursor Version {version} Update"

        except Exception as e:
            print(f"   âŒ æŸ¥æ‰¾æ ‡é¢˜å¤±è´¥: {e}")
            return f"Cursor Version {version} Update"

    def _find_version_content(self, soup: BeautifulSoup, version: str) -> str:
        """æŸ¥æ‰¾ç‰ˆæœ¬ç›¸å…³çš„å†…å®¹"""
        try:
            content_parts = []

            # æŸ¥æ‰¾æ‰€æœ‰h3æ ‡ç­¾ï¼ˆåŠŸèƒ½æè¿°ï¼‰
            h3_tags = soup.find_all("h3")

            for h3 in h3_tags:
                h3_text = h3.get_text().strip()

                # è·³è¿‡ç©ºå†…å®¹
                if not h3_text or len(h3_text) < 3:
                    continue

                # æ·»åŠ åŠŸèƒ½ç›¸å…³çš„å†…å®¹
                if any(
                    keyword in h3_text.lower()
                    for keyword in [
                        "agent",
                        "planning",
                        "context",
                        "tab",
                        "memory",
                        "search",
                        "improvement",
                        "feature",
                        "better",
                        "faster",
                        "new",
                        "background",
                        "slack",
                        "to-do",
                        "todo",
                        "queued",
                        "messages",
                        "pr",
                        "indexing",
                        "embeddings",
                        "semantic",
                        "merge",
                        "conflicts",
                    ]
                ):
                    content_parts.append(h3_text)

                # é™åˆ¶å†…å®¹æ•°é‡
                if len(content_parts) >= 10:
                    break

            # æŸ¥æ‰¾æ”¹è¿›é¡¹ç›®çš„åˆ†ç±»ï¼ˆImprovements, Fixes, Patchesï¼‰
            categories = ["Improvements", "Fixes", "Patches"]
            for category in categories:
                category_elements = soup.find_all(
                    string=lambda text: text and category in text
                )
                for element in category_elements:
                    parent = element.parent
                    if parent:
                        # æŸ¥æ‰¾æ•°å­—ï¼ˆå¦‚ "Improvements (7)"ï¼‰
                        category_text = parent.get_text().strip()
                        if "(" in category_text and ")" in category_text:
                            content_parts.append(category_text)

            # æŸ¥æ‰¾æ®µè½æè¿°
            paragraphs = soup.find_all("p")
            for p in paragraphs:
                p_text = p.get_text().strip()
                if len(p_text) > 20 and any(
                    keyword in p_text.lower()
                    for keyword in [
                        "agent",
                        "cursor",
                        "background",
                        "slack",
                        "feature",
                        "improvement",
                        "plan",
                        "task",
                        "context",
                        "chat",
                        "update",
                    ]
                ):
                    content_parts.append(p_text)
                    if len(content_parts) >= 15:
                        break

            # è¿”å›å†…å®¹
            if content_parts:
                return "\n".join(content_parts[:10])  # è¿”å›å‰10ä¸ªå†…å®¹
            else:
                return "New features and improvements for Cursor IDE"

        except Exception as e:
            print(f"   âŒ æŸ¥æ‰¾å†…å®¹å¤±è´¥: {e}")
            return "New features and improvements for Cursor IDE"

    def _extract_title_near_version(self, soup: BeautifulSoup, version: str) -> str:
        """æå–ç‰ˆæœ¬é™„è¿‘çš„æ ‡é¢˜"""
        try:
            # æŸ¥æ‰¾æ‰€æœ‰æ ‡é¢˜
            headers = soup.find_all(["h1", "h2", "h3"])

            # æŸ¥æ‰¾ç‰ˆæœ¬å·
            version_element = soup.find(
                string=lambda text: text and text.strip() == version
            )

            if not version_element:
                return f"Cursor {version} Update"

            # æŸ¥æ‰¾æœ€æ¥è¿‘ç‰ˆæœ¬å·çš„æ ‡é¢˜
            best_title = None
            min_distance = float("inf")

            for header in headers:
                try:
                    # è®¡ç®—æ ‡é¢˜ä¸ç‰ˆæœ¬å·çš„è·ç¦»ï¼ˆç®€å•çš„æ–‡æœ¬ä½ç½®æ¯”è¾ƒï¼‰
                    header_text = header.get_text().strip()

                    # è·³è¿‡ä¸»æ ‡é¢˜
                    if header_text.lower() in ["changelog", "cursor changelog"]:
                        continue

                    # å¦‚æœæ ‡é¢˜å†…å®¹æœ‰æ„ä¹‰ï¼Œè®¡ç®—è·ç¦»
                    if len(header_text) > 5:
                        # è·å–å…ƒç´ åœ¨é¡µé¢ä¸­çš„ä½ç½®
                        version_pos = str(soup).find(str(version_element))
                        header_pos = str(soup).find(str(header))

                        if version_pos != -1 and header_pos != -1:
                            distance = abs(version_pos - header_pos)
                            if distance < min_distance:
                                min_distance = distance
                                best_title = header_text

                except Exception:
                    continue

            return best_title if best_title else f"Cursor {version} Update"

        except Exception as e:
            print(f"   âŒ æå–æ ‡é¢˜å¤±è´¥: {e}")
            return f"Cursor {version} Update"

    def _extract_content_near_version(self, soup: BeautifulSoup, version: str) -> str:
        """æå–ç‰ˆæœ¬é™„è¿‘çš„å†…å®¹"""
        try:
            # æŸ¥æ‰¾ç‰ˆæœ¬å·é™„è¿‘çš„æ‰€æœ‰h3æ ‡ç­¾ï¼ˆåŠŸèƒ½æè¿°ï¼‰
            content_parts = []

            # æŸ¥æ‰¾æ‰€æœ‰h3æ ‡ç­¾
            h3_tags = soup.find_all("h3")

            # è·å–ç‰ˆæœ¬å·çš„ä½ç½®
            version_element = soup.find(
                string=lambda text: text and text.strip() == version
            )

            if not version_element:
                return "No content available"

            # ç®€å•æ–¹æ³•ï¼šè·å–é¡µé¢ä¸­è¯¥ç‰ˆæœ¬é™„è¿‘çš„æ‰€æœ‰h3æ ‡ç­¾
            page_html = str(soup)
            version_pos = page_html.find(version)

            # æŸ¥æ‰¾ç‰ˆæœ¬å·å‰åçš„å†…å®¹
            nearby_content = []

            for h3 in h3_tags:
                h3_text = h3.get_text().strip()

                # è·³è¿‡ç©ºå†…å®¹
                if not h3_text or len(h3_text) < 3:
                    continue

                # æ·»åŠ æœ‰æ„ä¹‰çš„åŠŸèƒ½æè¿°
                if any(
                    keyword in h3_text.lower()
                    for keyword in [
                        "agent",
                        "planning",
                        "context",
                        "tab",
                        "memory",
                        "search",
                        "improvement",
                        "feature",
                        "better",
                        "faster",
                        "new",
                    ]
                ):
                    nearby_content.append(h3_text)

                # é™åˆ¶å†…å®¹æ•°é‡
                if len(nearby_content) >= 10:
                    break

            # å¦‚æœæ‰¾åˆ°å†…å®¹ï¼Œè¿”å›å‰å‡ ä¸ª
            if nearby_content:
                return "\n".join(nearby_content[:8])  # è¿”å›å‰8ä¸ªåŠŸèƒ½
            else:
                return "New features and improvements"

        except Exception as e:
            print(f"   âŒ æå–å†…å®¹å¤±è´¥: {e}")
            return "No content available"

    def _estimate_release_date(self, version: str) -> str:
        """ä¼°ç®—ç‰ˆæœ¬å‘å¸ƒæ—¥æœŸ"""
        try:
            # åŸºäºç‰ˆæœ¬å·ä¼°ç®—æ—¥æœŸ
            parts = version.split(".")
            major = int(parts[0])
            minor = int(parts[1])
            patch = int(parts[2]) if len(parts) > 2 else 0

            # ä¼°ç®—å‘å¸ƒæ—¥æœŸï¼ˆè¿™é‡Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
            from datetime import datetime, timedelta

            # å‡è®¾ä»2024å¹´å¼€å§‹
            base_date = datetime(2024, 1, 1)

            # æ¯ä¸ªå¤§ç‰ˆæœ¬é—´éš”çº¦3ä¸ªæœˆï¼Œå°ç‰ˆæœ¬é—´éš”çº¦1å‘¨
            estimated_days = major * 90 + minor * 7 + patch * 1

            estimated_date = base_date + timedelta(days=estimated_days)

            return estimated_date.strftime("%Y-%m-%d")

        except Exception:
            # å¦‚æœä¼°ç®—å¤±è´¥ï¼Œè¿”å›å½“å‰æ—¥æœŸ
            from datetime import datetime

            return datetime.now().strftime("%Y-%m-%d")

    def _parse_by_containers(self, soup: BeautifulSoup) -> List[Dict]:
        """é€šè¿‡å®¹å™¨ç»“æ„è§£æç‰ˆæœ¬ä¿¡æ¯"""
        versions = []

        try:
            # æŸ¥æ‰¾å¯èƒ½åŒ…å«ç‰ˆæœ¬ä¿¡æ¯çš„å®¹å™¨
            containers = soup.find_all(["div", "section", "article"])

            for container in containers:
                text = container.get_text()

                # æŸ¥æ‰¾ç‰ˆæœ¬å·
                version_match = re.search(r"(\d+\.\d+)", text)
                if version_match:
                    version = version_match.group(1)

                    # æŸ¥æ‰¾æ—¥æœŸ
                    date_match = re.search(r"([A-Za-z]+ \d+, \d{4})", text)
                    date = date_match.group(1) if date_match else "January 1, 2025"

                    # æå–æ ‡é¢˜å’Œå†…å®¹
                    title = self._extract_title_from_container(container)
                    content = self._extract_content_from_container(container)

                    versions.append(
                        {
                            "version": version,
                            "release_date": self._parse_date(date),
                            "title": title,
                            "content": content,
                        }
                    )

            return versions

        except Exception as e:
            print(f"âŒ å®¹å™¨è§£æå¤±è´¥: {e}")
            return []

    def _parse_by_patterns(self, soup: BeautifulSoup) -> List[Dict]:
        """é€šè¿‡æ¨¡å¼åŒ¹é…è§£æç‰ˆæœ¬ä¿¡æ¯"""
        versions = []

        try:
            # è·å–é¡µé¢æ‰€æœ‰æ–‡æœ¬
            page_text = soup.get_text()

            # åŸºäºå·²çŸ¥çš„ç‰ˆæœ¬æ¨¡å¼ï¼Œå°è¯•æå–ä¿¡æ¯
            known_versions = ["1.2", "1.1", "1.0", "0.50", "0.49"]

            for version in known_versions:
                if version in page_text:
                    # æŸ¥æ‰¾ç‰ˆæœ¬é™„è¿‘çš„æ—¥æœŸ
                    version_pos = page_text.find(version)
                    surrounding_text = page_text[
                        max(0, version_pos - 100) : version_pos + 500
                    ]

                    date_match = re.search(r"([A-Za-z]+ \d+, \d{4})", surrounding_text)
                    date = date_match.group(1) if date_match else "January 1, 2025"

                    # æå–æ ‡é¢˜å’Œå†…å®¹
                    title = self._extract_title_from_text(surrounding_text, version)
                    content = self._extract_content_from_text(page_text, version)

                    versions.append(
                        {
                            "version": version,
                            "release_date": self._parse_date(date),
                            "title": title,
                            "content": content,
                        }
                    )

            return versions

        except Exception as e:
            print(f"âŒ æ¨¡å¼è§£æå¤±è´¥: {e}")
            return []

    def _extract_title_from_container(self, container) -> str:
        """ä»å®¹å™¨ä¸­æå–æ ‡é¢˜"""
        try:
            # æŸ¥æ‰¾æ ‡é¢˜å…ƒç´ 
            title_elements = container.find_all(["h1", "h2", "h3", "h4"])
            for element in title_elements:
                text = element.get_text().strip()
                if len(text) > 10 and len(text) < 100:
                    return text

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡é¢˜å…ƒç´ ï¼ŒæŸ¥æ‰¾å¯èƒ½çš„æ ‡é¢˜æ–‡æœ¬
            texts = container.find_all(text=True)
            for text in texts:
                text = text.strip()
                if (
                    len(text) > 10
                    and len(text) < 100
                    and any(
                        keyword in text.lower()
                        for keyword in [
                            "agent",
                            "update",
                            "feature",
                            "improvement",
                            "new",
                            "better",
                            "faster",
                        ]
                    )
                ):
                    return text

            return "Cursor Update"

        except Exception:
            return "Cursor Update"

    def _extract_content_from_container(self, container) -> str:
        """ä»å®¹å™¨ä¸­æå–å†…å®¹"""
        try:
            # æå–æ‰€æœ‰æ®µè½å’Œåˆ—è¡¨å†…å®¹
            content_elements = container.find_all(["p", "li", "div"])
            content_parts = []

            for element in content_elements:
                text = element.get_text().strip()
                if len(text) > 20:
                    content_parts.append(text)

            return (
                "\n\n".join(content_parts) if content_parts else "No content available"
            )

        except Exception:
            return "No content available"

    def _extract_title_from_text(self, text: str, version: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–æ ‡é¢˜"""
        try:
            lines = text.split("\n")
            for line in lines:
                line = line.strip()
                if (
                    len(line) > 10
                    and len(line) < 100
                    and any(
                        keyword in line.lower()
                        for keyword in [
                            "agent",
                            "update",
                            "feature",
                            "improvement",
                            "new",
                            "better",
                            "faster",
                        ]
                    )
                ):
                    return line

            return f"Cursor {version} Update"

        except Exception:
            return f"Cursor {version} Update"

    def _extract_content_from_text(self, text: str, version: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–å†…å®¹"""
        try:
            # æŸ¥æ‰¾ç‰ˆæœ¬å·çš„ä½ç½®
            version_pos = text.find(version)
            if version_pos == -1:
                return "No content available"

            # æå–ç‰ˆæœ¬å·åé¢çš„å†…å®¹ï¼ˆåˆ°ä¸‹ä¸€ä¸ªç‰ˆæœ¬å·æˆ–å›ºå®šé•¿åº¦ï¼‰
            content_start = version_pos + len(version)
            content_end = content_start + 2000  # é™åˆ¶å†…å®¹é•¿åº¦

            # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªç‰ˆæœ¬å·
            next_version_pos = -1
            for v in ["1.2", "1.1", "1.0", "0.50", "0.49"]:
                if v != version:
                    pos = text.find(v, content_start)
                    if pos != -1 and (next_version_pos == -1 or pos < next_version_pos):
                        next_version_pos = pos

            if next_version_pos != -1:
                content_end = next_version_pos

            content = text[content_start:content_end]

            # æ¸…ç†å†…å®¹
            content = re.sub(r"\s+", " ", content)  # åˆå¹¶å¤šä¸ªç©ºæ ¼
            content = content.strip()

            return content if content else "No content available"

        except Exception:
            return "No content available"

    def _is_date(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦æ˜¯æ—¥æœŸæ ¼å¼"""
        date_patterns = [
            r"[A-Za-z]+ \d+, \d{4}",  # January 1, 2024
            r"\d{4}-\d{2}-\d{2}",  # 2024-01-01
            r"\d{2}/\d{2}/\d{4}",  # 01/01/2024
        ]

        for pattern in date_patterns:
            if re.match(pattern, text.strip()):
                return True
        return False

    def _is_valid_cursor_version(self, version: str) -> bool:
        """éªŒè¯æ˜¯å¦æ˜¯æœ‰æ•ˆçš„Cursorç‰ˆæœ¬å·"""
        if not version or not re.match(r"^\d+\.\d+$", version):
            return False

        try:
            parts = version.split(".")
            if len(parts) != 2:
                return False

            major = int(parts[0])
            minor = int(parts[1])

            # Cursorç‰ˆæœ¬å·çš„åˆç†èŒƒå›´:
            # - 1.x ç³»åˆ—: 1.0, 1.1, 1.2, ...
            # - 0.x ç³»åˆ—: 0.40+ï¼ˆå†å²ç‰ˆæœ¬ï¼‰
            if (major == 1 and minor >= 0) or (major == 0 and 40 <= minor <= 99):
                return True

            return False

        except (ValueError, IndexError):
            return False

    def _validate_version_context(self, element) -> bool:
        """éªŒè¯ç‰ˆæœ¬å·çš„ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿æ˜¯çœŸæ­£çš„ç‰ˆæœ¬å·è€Œéå…¶ä»–æ•°å­—"""
        try:
            # æ£€æŸ¥å…ƒç´ çš„çˆ¶å®¹å™¨å’Œå…„å¼Ÿå…ƒç´ 
            parent = element.parent
            if not parent:
                return True  # å¦‚æœæ²¡æœ‰çˆ¶å…ƒç´ ï¼Œé»˜è®¤æœ‰æ•ˆ

            # è·å–å‘¨å›´çš„æ–‡æœ¬å†…å®¹
            surrounding_text = ""

            # æ£€æŸ¥å‰åçš„å…„å¼Ÿå…ƒç´ 
            prev_sibling = element.previous_sibling
            if prev_sibling:
                surrounding_text += str(prev_sibling)

            next_sibling = element.next_sibling
            if next_sibling:
                surrounding_text += str(next_sibling)

            # æ£€æŸ¥çˆ¶å…ƒç´ çš„æ–‡æœ¬
            if parent:
                surrounding_text += parent.get_text()

            # è½¬æ¢ä¸ºå°å†™è¿›è¡Œå…³é”®è¯æ£€æŸ¥
            context_text = surrounding_text.lower()

            # ç‰ˆæœ¬å·ç›¸å…³çš„å…³é”®è¯
            version_keywords = [
                "version",
                "v",
                "release",
                "update",
                "cursor",
                "changelog",
                "july",
                "june",
                "may",
                "april",
                "march",
                "february",
                "january",
                "2024",
                "2025",
                "agent",
                "planning",
                "feature",
                "improvement",
            ]

            # éç‰ˆæœ¬å·çš„å…³é”®è¯ï¼ˆæ’é™¤è¿™äº›ï¼‰
            non_version_keywords = [
                "price",
                "cost",
                "dollar",
                "usd",
                "payment",
                "billing",
                "width",
                "height",
                "size",
                "pixel",
                "px",
                "rem",
                "em",
                "rating",
                "star",
                "score",
                "percentage",
                "%",
            ]

            # å¦‚æœåŒ…å«éç‰ˆæœ¬å·å…³é”®è¯ï¼Œè¿”å›False
            for keyword in non_version_keywords:
                if keyword in context_text:
                    return False

            # å¦‚æœåŒ…å«ç‰ˆæœ¬å·å…³é”®è¯ï¼Œè¿”å›True
            for keyword in version_keywords:
                if keyword in context_text:
                    return True

            # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„å…³é”®è¯ï¼Œæ£€æŸ¥æ˜¯å¦åœ¨åˆç†çš„HTMLç»“æ„ä¸­
            # ç‰ˆæœ¬å·é€šå¸¸åœ¨ç‰¹å®šçš„å®¹å™¨ä¸­
            parent_classes = parent.get("class", []) if parent else []
            parent_class_str = " ".join(parent_classes).lower()

            # å¸¸è§çš„ç‰ˆæœ¬å·å®¹å™¨ç±»å
            version_container_keywords = [
                "version",
                "tag",
                "badge",
                "label",
                "release",
                "update",
                "flex",
                "items-center",
                "card",
                "container",
            ]

            for keyword in version_container_keywords:
                if keyword in parent_class_str:
                    return True

            # é»˜è®¤æƒ…å†µä¸‹ï¼Œå¦‚æœæ²¡æœ‰æ˜ç¡®çš„åå¯¹ç†ç”±ï¼Œè®¤ä¸ºæ˜¯æœ‰æ•ˆçš„
            return True

        except Exception:
            # å¦‚æœéªŒè¯è¿‡ç¨‹å‡ºé”™ï¼Œé»˜è®¤è®¤ä¸ºæœ‰æ•ˆ
            return True

    def _filter_cursor_versions(self, versions: List[str]) -> List[str]:
        """æ™ºèƒ½è¿‡æ»¤å’Œæ’åºCursorç‰ˆæœ¬å·"""
        filtered_versions = []

        # å·²çŸ¥çš„Cursorç‰ˆæœ¬å·ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        known_cursor_versions = [
            "1.2",
            "1.1",
            "1.0",  # 1.x ç³»åˆ—
            "0.50",
            "0.49",
            "0.48",
            "0.47",
            "0.46",
            "0.45",  # 0.x ç³»åˆ—
        ]

        # é¦–å…ˆæ·»åŠ å·²çŸ¥ç‰ˆæœ¬ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
        for known_version in known_cursor_versions:
            if known_version in versions:
                filtered_versions.append(known_version)

        # ç„¶åæ·»åŠ æœªçŸ¥ä½†ç¬¦åˆæ ¼å¼çš„æ–°ç‰ˆæœ¬
        for version in versions:
            if version not in filtered_versions:
                parts = version.split(".")
                major, minor = int(parts[0]), int(parts[1])

                # æ”¯æŒæœªæ¥çš„ç‰ˆæœ¬å·
                if (major == 1 and minor >= 0) or (major == 0 and minor >= 40):
                    filtered_versions.append(version)

        # æŒ‰ç‰ˆæœ¬å·æ’åºï¼ˆé™åºï¼‰
        filtered_versions.sort(
            key=lambda x: [int(v) for v in x.split(".")], reverse=True
        )

        return filtered_versions

    def _parse_date(self, date_str: str) -> str:
        """è§£ææ—¥æœŸå­—ç¬¦ä¸²ä¸ºISOæ ¼å¼"""
        try:
            # å¤„ç† "July 3, 2025" æ ¼å¼
            if re.match(r"[A-Za-z]+ \d+, \d{4}", date_str):
                date_obj = datetime.strptime(date_str, "%B %d, %Y")
                return date_obj.strftime("%Y-%m-%d")

            # å¤„ç† "2025-07-03" æ ¼å¼
            elif re.match(r"\d{4}-\d{2}-\d{2}", date_str):
                return date_str

            # å¤„ç†å…¶ä»–æ ¼å¼...
            else:
                return "2025-01-01"

        except Exception:
            return "2025-01-01"

    def _get_fallback_versions(self) -> List[Dict]:
        """è·å–å¤‡ç”¨ç‰ˆæœ¬æ•°æ®ï¼ˆå½“ç½‘ç«™è§£æå¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        print("ğŸ“‹ ä½¿ç”¨å¤‡ç”¨ç‰ˆæœ¬æ•°æ®")

        return [
            {
                "version": "1.2",
                "release_date": "2025-07-03",
                "title": "Agent Planning, Better Context & Faster Tab",
                "content": """
## Agent Planning, Better Context & Faster Tab

### Agent To-dos
Agents now plan ahead with structured to-do lists, making long-horizon tasks easier to understand and track.

The agent breaks down longer tasks with dependencies, visible to you in chat and streamed into Slack when relevant. It can update this list as work progresses, keeping context fresh and interactions predictable.

### Queued messages
You can now queue follow-up messages for Agent once it's done with current task. Just type your instructions and send. Once in queue, you can reorder tasks and start executing without waiting.

### Memories (now GA)
Memories is now GA. Since 1.0, we've improved memory generation quality, added in-editor UI polish, and introduced user approvals for background-generated memories to preserve trust.

### PR indexing & search
Cursor now indexes and summarizes PRs much like it does files. You can search old PRs semantically or explicitly fetch a PR, issue, commit, or branch into context.

### Improved embeddings for semantic search
Codebase search is now much more accurate with our new embedding model. We've also re-tuned prompts to yield cleaner, more focused results.

### Faster Tab
Tab completions are now ~100ms faster, and TTFT has been reduced by 30%. We made this possible by restructuring our memory management system and optimizing data transfer pathways.

### Let Agent resolve merge conflicts
When merge conflicts occur, Agent can now attempt to resolve them for you. Click Resolve in Chat and relevant context will be added to resolve the conflict.

### Background Agent improvements
Several improvements to Background Agents make them more predictable and resilient:
- PRs follow your team's template
- Changes to the agent branch are auto-pulled in
- Conflicts (like rebases) are now surfaced as actionable follow-ups
- You can commit directly from the sidebar
- Slack and web deeplinks open the associated repo, even if you don't have it open
            """,
            },
            {
                "version": "1.1",
                "release_date": "2025-06-12",
                "title": "Background Agents in Slack",
                "content": """
## Background Agents in Slack

You can now launch Background Agents directly from Slack by mentioning @Cursor. Agents can read the thread, understand what's going on, and create PRs in GitHub, all without leaving the conversation.

### Use Cursor where your team works
Mention @Cursor in any thread with a prompt. Agents run remotely in a secure environment and you'll get updates directly in Slack, including links to Cursor and GitHub, when the work is done.

### Agents understand context
Cursor reads the entire Slack thread before starting, so Background Agents understand the full context when you reference previous discussions or issues.

### Getting started
To use Background Agents in Slack, an admin needs to set up the integration first. Check out our setup documentation or ask your workspace admin to connect Cursor from the Dashboard â†’ Integrations page.
            """,
            },
            {
                "version": "1.0",
                "release_date": "2025-06-04",
                "title": "BugBot, Background Agent access to everyone, and one-click MCP install",
                "content": """
## BugBot, Background Agent access to everyone, and one-click MCP install

### Automatic code review with BugBot
BugBot automatically reviews your PRs and catches potential bugs and issues. When an issue is found, BugBot leaves a comment on your PRs in GitHub.

### Background Agent for everyone
Since we released Background Agent, our remote coding agent, in early access a few weeks ago, early signals have been positive. We're now excited to expand Background Agent to all users!

### Agent in Jupyter Notebooks
Cursor can now implement changes in Jupyter Notebooks! Agent will now create and edit multiple cells directly inside of Jupyter, a significant improvement for research and data science tasks.

### Memories
With Memories, Cursor can remember facts from conversations and reference them in the future. Memories are stored per project on an individual level, and can be managed from Settings.

### MCP one-click install and OAuth support
You can now set up MCP servers in Cursor with one click, and together with OAuth support, you can easily authenticate servers that support it.

### Richer Chat responses
Cursor can now render visualizations inside of a conversation. In particular, Mermaid diagrams and Markdown tables can now be generated and viewed in the same place!
            """,
            },
        ]

    def _translate_content(self, content: str) -> str:
        """ç¿»è¯‘å†…å®¹åˆ°ä¸­æ–‡"""
        try:
            # æ·»åŠ å®Œæ•´çš„è¯·æ±‚å¤´æ¥è§£å†³ 428 é”™è¯¯
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {settings.deepseek_api_key}",
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Accept": "application/json",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
                "Cache-Control": "no-cache",
            }

            data = {
                "model": settings.ai_model,
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯ç¿»è¯‘å‘˜ï¼Œä¸“é—¨ç¿»è¯‘è½¯ä»¶å¼€å‘ç›¸å…³çš„æ–‡æ¡£ã€‚è¯·å°†ä»¥ä¸‹è‹±æ–‡å†…å®¹ç¿»è¯‘æˆä¸­æ–‡ï¼Œä¿æŒæŠ€æœ¯æœ¯è¯­çš„å‡†ç¡®æ€§å’Œä¸“ä¸šæ€§ã€‚é‡è¦ï¼šè¯·ä¿æŒåŸæ–‡çš„æ®µè½ç»“æ„å’Œæ ¼å¼ï¼Œä½¿ç”¨å¥å·ï¼ˆã€‚ï¼‰åˆ†éš”å¥å­ï¼Œä¸è¦ä½¿ç”¨###æˆ–***ç­‰æ ‡è®°ç¬¦å·ã€‚",
                    },
                    {
                        "role": "user",
                        "content": f"è¯·ç¿»è¯‘ä»¥ä¸‹ Cursor æ›´æ–°æ—¥å¿—å†…å®¹åˆ°ä¸­æ–‡ï¼Œä¿æŒæ®µè½åˆ†éš”å’Œæ ¼å¼ç»“æ„ï¼š\n\n{content}",
                    },
                ],
                "max_tokens": 2000,
                "temperature": 0.3,
                "stream": False,
            }

            # é‡è¯•æœºåˆ¶
            for attempt in range(3):
                try:
                    print(f"      ğŸ”„ ç¬¬ {attempt + 1}/3 æ¬¡å°è¯•...", end="", flush=True)
                    start_time = time.time()
                    response = requests.post(
                        settings.deepseek_api_url,
                        headers=headers,
                        json=data,
                        timeout=120,
                    )

                    elapsed_time = time.time() - start_time
                    print(f" (ç”¨æ—¶ {elapsed_time:.1f}s)")

                    if response.status_code == 200:
                        result = response.json()
                        if "choices" in result and len(result["choices"]) > 0:
                            translated_text = result["choices"][0]["message"]["content"]
                            return translated_text
                        else:
                            print(f"      âŒ å“åº”æ ¼å¼é”™è¯¯: {result}")
                    else:
                        print(f"      âŒ API å“åº”é”™è¯¯: {response.status_code}")
                        if attempt < 2:
                            print(f"      â³ ç­‰å¾… {attempt + 1} ç§’åé‡è¯•...")
                            time.sleep(attempt + 1)

                except requests.exceptions.Timeout:
                    print(f"      â° è¯·æ±‚è¶…æ—¶ï¼Œé‡è¯•ä¸­...")
                    continue
                except requests.exceptions.RequestException as e:
                    print(f"      ğŸ”Œ è¯·æ±‚å¼‚å¸¸: {e}")
                    if attempt < 2:
                        continue
                except Exception as e:
                    print(f"      â— æœªçŸ¥é”™è¯¯: {e}")
                    if attempt < 2:
                        continue

            return "âŒ ç¿»è¯‘å¤±è´¥ï¼šæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†"

        except Exception as e:
            print(f"      âŒ ç¿»è¯‘é…ç½®é”™è¯¯: {e}")
            return f"âŒ ç¿»è¯‘å¤±è´¥: {str(e)}"

    def _translate_title(self, title: str) -> str:
        """ç¿»è¯‘æ ‡é¢˜åˆ°ä¸­æ–‡"""
        try:
            # æ·»åŠ å®Œæ•´çš„è¯·æ±‚å¤´æ¥è§£å†³ 428 é”™è¯¯
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {settings.deepseek_api_key}",
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Accept": "application/json",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
                "Cache-Control": "no-cache",
            }

            data = {
                "model": settings.ai_model,
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯ç¿»è¯‘å‘˜ã€‚è¯·å°†ä»¥ä¸‹è‹±æ–‡æ ‡é¢˜ç¿»è¯‘æˆä¸­æ–‡ï¼Œä¿æŒç®€æ´å’Œä¸“ä¸šæ€§ã€‚åªè¿”å›ç¿»è¯‘ç»“æœï¼Œä¸éœ€è¦å…¶ä»–è§£é‡Šã€‚",
                    },
                    {"role": "user", "content": f"è¯·ç¿»è¯‘ï¼š{title}"},
                ],
                "max_tokens": 100,
                "temperature": 0.3,
                "stream": False,
            }

            # é‡è¯•æœºåˆ¶
            for attempt in range(2):
                try:
                    print(f"      ğŸ”„ ç¬¬ {attempt + 1}/2 æ¬¡å°è¯•...", end="", flush=True)
                    start_time = time.time()
                    response = requests.post(
                        settings.deepseek_api_url,
                        headers=headers,
                        json=data,
                        timeout=60,
                    )

                    elapsed_time = time.time() - start_time
                    print(f" (ç”¨æ—¶ {elapsed_time:.1f}s)")

                    if response.status_code == 200:
                        result = response.json()
                        if "choices" in result and len(result["choices"]) > 0:
                            translated_title = result["choices"][0]["message"][
                                "content"
                            ].strip()
                            return translated_title
                        else:
                            print(f"      âŒ å“åº”æ ¼å¼é”™è¯¯: {result}")
                    else:
                        print(f"      âŒ API å“åº”é”™è¯¯: {response.status_code}")
                        if attempt < 1:
                            print(f"      â³ ç­‰å¾… {attempt + 1} ç§’åé‡è¯•...")
                            time.sleep(attempt + 1)

                except requests.exceptions.Timeout:
                    print(f"      â° è¯·æ±‚è¶…æ—¶ï¼Œé‡è¯•ä¸­...")
                    continue
                except requests.exceptions.RequestException as e:
                    print(f"      ğŸ”Œ è¯·æ±‚å¼‚å¸¸: {e}")
                    if attempt < 1:
                        continue
                except Exception as e:
                    print(f"      â— æœªçŸ¥é”™è¯¯: {e}")
                    if attempt < 1:
                        continue

            return "âŒ æ ‡é¢˜ç¿»è¯‘å¤±è´¥"

        except Exception as e:
            print(f"      âŒ æ ‡é¢˜ç¿»è¯‘é…ç½®é”™è¯¯: {e}")
            return "âŒ æ ‡é¢˜ç¿»è¯‘å¤±è´¥"

    def _analyze_with_deepseek(
        self, original_content: str, translated_content: str
    ) -> str:
        """ä½¿ç”¨ DeepSeek åˆ†ææ€»ç»“"""
        try:
            # æ·»åŠ å®Œæ•´çš„è¯·æ±‚å¤´æ¥è§£å†³ 428 é”™è¯¯
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {settings.deepseek_api_key}",
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Accept": "application/json",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
                "Cache-Control": "no-cache",
            }

            data = {
                "model": settings.ai_model,
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯åˆ†æå¸ˆï¼Œä¸“é—¨åˆ†æè½¯ä»¶æ›´æ–°å’ŒæŠ€æœ¯è¶‹åŠ¿ã€‚è¯·åˆ†æä»¥ä¸‹ Cursor æ›´æ–°å†…å®¹ï¼Œæä¾›æ·±åº¦è§è§£å’Œæ€»ç»“ã€‚è¯·æŒ‰æ®µè½åˆ†éš”å†…å®¹ï¼Œä½¿ç”¨å¥å·ï¼ˆã€‚ï¼‰åˆ†éš”å¥å­ï¼Œä¸è¦ä½¿ç”¨###æˆ–***ç­‰æ ‡è®°ç¬¦å·ã€‚",
                    },
                    {
                        "role": "user",
                        "content": f"""
è¯·åˆ†æä»¥ä¸‹ Cursor æ›´æ–°å†…å®¹ï¼Œæä¾›æ·±åº¦è§è§£å’Œæ€»ç»“ï¼š

åŸæ–‡ï¼š
{original_content}

ä¸­æ–‡ç¿»è¯‘ï¼š
{translated_content}

è¯·ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢è¿›è¡Œåˆ†æï¼š
1. ä¸»è¦åŠŸèƒ½æ›´æ–°å’Œæ”¹è¿›
2. æŠ€æœ¯åˆ›æ–°ç‚¹
3. å¯¹å¼€å‘è€…çš„å½±å“
4. å¸‚åœºç«äº‰ä¼˜åŠ¿
5. æœªæ¥å‘å±•è¶‹åŠ¿
6. ç½‘ç»œæœç´¢ç›¸å…³ä¿¡æ¯ï¼ˆåŸºäºä½ çš„çŸ¥è¯†ï¼Œåˆ†æè¿™äº›æ›´æ–°åœ¨æŠ€æœ¯ç¤¾åŒºã€å¼€å‘è€…è®ºå›ã€ç¤¾äº¤åª’ä½“ç­‰ç½‘ç»œå¹³å°çš„è®¨è®ºçƒ­åº¦å’Œå…³æ³¨ç‚¹ï¼‰
7. ç”¨æˆ·/å¼€å‘è€…å“åº”å¦‚ä½•ï¼ˆé¢„æµ‹å’Œåˆ†æå¼€å‘è€…ç¤¾åŒºå¯¹è¿™äº›æ›´æ–°çš„å¯èƒ½ååº”ã€æ¥å—åº¦å’Œä½¿ç”¨æƒ…å†µï¼‰

è¯·æä¾›è¯¦ç»†çš„åˆ†æï¼Œæ¯ä¸ªæ–¹é¢éƒ½è¦æœ‰å…·ä½“çš„è®ºè¿°å’Œè§è§£ã€‚
                        """,
                    },
                ],
                "max_tokens": 2000,
                "temperature": 0.7,
                "stream": False,
            }

            # é‡è¯•æœºåˆ¶
            for attempt in range(3):
                try:
                    print(f"      ğŸ”„ ç¬¬ {attempt + 1}/3 æ¬¡å°è¯•...", end="", flush=True)
                    start_time = time.time()
                    response = requests.post(
                        settings.deepseek_api_url,
                        headers=headers,
                        json=data,
                        timeout=120,
                    )

                    elapsed_time = time.time() - start_time
                    print(f" (ç”¨æ—¶ {elapsed_time:.1f}s)")

                    if response.status_code == 200:
                        result = response.json()
                        if "choices" in result and len(result["choices"]) > 0:
                            analysis_result = result["choices"][0]["message"]["content"]
                            return analysis_result
                        else:
                            print(f"      âŒ å“åº”æ ¼å¼é”™è¯¯: {result}")
                    else:
                        print(f"      âŒ API å“åº”é”™è¯¯: {response.status_code}")
                        if attempt < 2:
                            print(f"      â³ ç­‰å¾… {attempt + 1} ç§’åé‡è¯•...")
                            time.sleep(attempt + 1)

                except requests.exceptions.Timeout:
                    print(f"      â° è¯·æ±‚è¶…æ—¶ï¼Œé‡è¯•ä¸­...")
                    continue
                except requests.exceptions.RequestException as e:
                    print(f"      ğŸ”Œ è¯·æ±‚å¼‚å¸¸: {e}")
                    if attempt < 2:
                        continue
                except Exception as e:
                    print(f"      â— æœªçŸ¥é”™è¯¯: {e}")
                    if attempt < 2:
                        continue

            return "âŒ åˆ†æå¤±è´¥ï¼šæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†"

        except Exception as e:
            print(f"      âŒ åˆ†æé…ç½®é”™è¯¯: {e}")
            return f"âŒ åˆ†æå¤±è´¥: {str(e)}"

    def _translate_and_analyze_with_deepseek(self, title: str, content: str) -> Dict:
        """ä¸€æ¬¡æ€§å®Œæˆç¿»è¯‘å’Œåˆ†æ"""
        try:
            # æ·»åŠ å®Œæ•´çš„è¯·æ±‚å¤´æ¥è§£å†³ 428 é”™è¯¯
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {settings.deepseek_api_key}",
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Accept": "application/json",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
                "Cache-Control": "no-cache",
            }

            data = {
                "model": settings.ai_model,
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯ç¿»è¯‘å‘˜å’Œåˆ†æå¸ˆï¼Œä¸“é—¨å¤„ç†è½¯ä»¶å¼€å‘ç›¸å…³çš„æ–‡æ¡£ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¿”å›ç»“æœï¼Œä¿æŒåŸæ–‡çš„æ ¼å¼ç»“æ„ã€‚",
                    },
                    {
                        "role": "user",
                        "content": f"""
è¯·å¯¹ä»¥ä¸‹Cursor IDEæ›´æ–°è¿›è¡Œç¿»è¯‘å’Œåˆ†æï¼š

æ ‡é¢˜ï¼ˆè‹±æ–‡ï¼‰ï¼š{title}
å†…å®¹ï¼ˆè‹±æ–‡ï¼‰ï¼š{content}

ç¿»è¯‘è¦æ±‚ï¼š
1. ä¿æŒåŸæ–‡çš„æ®µè½ç»“æ„å’Œæ ¼å¼
2. ä¿ç•™åŸæ–‡ä¸­çš„æ ‡é¢˜å±‚çº§ï¼ˆ##, ###ï¼‰
3. ä¿æŒåˆ—è¡¨æ ¼å¼ï¼ˆ- æˆ–æ•°å­—åˆ—è¡¨ï¼‰
4. æŠ€æœ¯æœ¯è¯­ä½¿ç”¨å‡†ç¡®çš„ä¸­æ–‡ç¿»è¯‘
5. è¯­è¨€è¦æµç•…è‡ªç„¶ï¼Œç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
  "translated_title": "ä¸­æ–‡ç¿»è¯‘çš„æ ‡é¢˜ï¼ˆç®€æ´æ˜ç¡®ï¼‰",
  "translated_content": "ä¸­æ–‡ç¿»è¯‘çš„å†…å®¹ï¼ˆä¿æŒåŸæ–‡æ ¼å¼ç»“æ„ï¼Œä½¿ç”¨\\n\\nåˆ†éš”æ®µè½ï¼Œä½¿ç”¨\\nåˆ†éš”è¡Œï¼‰",
  "analysis": "è¯¦ç»†çš„æŠ€æœ¯åˆ†æï¼ˆç”¨ä¸­æ–‡ï¼ŒåŒ…æ‹¬ï¼š\\n\\n1. ä¸»è¦åŠŸèƒ½æ›´æ–°å’Œæ”¹è¿›åˆ†æ\\n- å…·ä½“åŠŸèƒ½ç‚¹åˆ†æ\\n- æŠ€æœ¯å®ç°ç‰¹ç‚¹\\n\\n2. æŠ€æœ¯åˆ›æ–°ç‚¹\\n- åˆ›æ–°æŠ€æœ¯è§£è¯»\\n- ä¸ç«å“å¯¹æ¯”\\n\\n3. å¯¹å¼€å‘è€…çš„å½±å“\\n- å¼€å‘æ•ˆç‡æå‡\\n- å­¦ä¹ æˆæœ¬è¯„ä¼°\\n\\n4. å¸‚åœºç«äº‰ä¼˜åŠ¿\\n- æ ¸å¿ƒç«äº‰åŠ›\\n- å¸‚åœºå®šä½åˆ†æï¼‰"
}}

é‡è¦ï¼šè¯·ç¡®ä¿è¿”å›ä¸¥æ ¼çš„JSONæ ¼å¼ï¼Œtranslated_contentå­—æ®µè¦ä¿æŒåŸæ–‡çš„æ®µè½ç»“æ„ã€‚
                        """,
                    },
                ],
                "max_tokens": 3000,
                "temperature": 0.2,
                "stream": False,
            }

            # é‡è¯•æœºåˆ¶
            for attempt in range(3):
                try:
                    print(f"      ğŸ”„ ç¬¬ {attempt + 1}/3 æ¬¡å°è¯•...", end="", flush=True)
                    start_time = time.time()
                    response = requests.post(
                        settings.deepseek_api_url,
                        headers=headers,
                        json=data,
                        timeout=120,
                    )

                    elapsed_time = time.time() - start_time
                    print(f" (ç”¨æ—¶ {elapsed_time:.1f}s)")

                    if response.status_code == 200:
                        result = response.json()
                        if "choices" in result and len(result["choices"]) > 0:
                            api_content = result["choices"][0]["message"]["content"]

                            # å°è¯•è§£æJSONå“åº”
                            try:
                                # æå–JSONéƒ¨åˆ†
                                json_start = api_content.find("{")
                                json_end = api_content.rfind("}") + 1

                                if json_start != -1 and json_end > json_start:
                                    json_str = api_content[json_start:json_end]
                                    parsed_result = json.loads(json_str)

                                    return {
                                        "translated_title": parsed_result.get(
                                            "translated_title", f"{title}ï¼ˆç¿»è¯‘å¤±è´¥ï¼‰"
                                        ),
                                        "translated_content": parsed_result.get(
                                            "translated_content",
                                            f"{content}ï¼ˆç¿»è¯‘å¤±è´¥ï¼‰",
                                        ),
                                        "analysis": parsed_result.get(
                                            "analysis", "åˆ†æå¤±è´¥"
                                        ),
                                    }
                                else:
                                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•
                                    return self._parse_fallback_response(
                                        api_content, title, content
                                    )

                            except json.JSONDecodeError:
                                # JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•
                                print(f"      âš ï¸ JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•...")
                                return self._parse_fallback_response(
                                    api_content, title, content
                                )
                        else:
                            print(f"      âŒ å“åº”æ ¼å¼é”™è¯¯: {result}")
                    else:
                        print(f"      âŒ API å“åº”é”™è¯¯: {response.status_code}")
                        if attempt < 2:
                            print(f"      â³ ç­‰å¾… {attempt + 1} ç§’åé‡è¯•...")
                            time.sleep(attempt + 1)

                except requests.exceptions.Timeout:
                    print(f"      â° è¯·æ±‚è¶…æ—¶ï¼Œé‡è¯•ä¸­...")
                    continue
                except requests.exceptions.RequestException as e:
                    print(f"      ğŸ”Œ è¯·æ±‚å¼‚å¸¸: {e}")
                    if attempt < 2:
                        continue
                except Exception as e:
                    print(f"      â— æœªçŸ¥é”™è¯¯: {e}")
                    if attempt < 2:
                        continue

            return {
                "translated_title": f"{title}ï¼ˆç¿»è¯‘å¤±è´¥ï¼‰",
                "translated_content": f"{content}ï¼ˆç¿»è¯‘å¤±è´¥ï¼‰",
                "analysis": "âŒ APIè°ƒç”¨å¤±è´¥ï¼šæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†",
            }

        except Exception as e:
            print(f"      âŒ ç¿»è¯‘å’Œåˆ†æé…ç½®é”™è¯¯: {e}")
            return {
                "translated_title": f"{title}ï¼ˆç¿»è¯‘å¤±è´¥ï¼‰",
                "translated_content": f"{content}ï¼ˆç¿»è¯‘å¤±è´¥ï¼‰",
                "analysis": f"âŒ é…ç½®é”™è¯¯: {str(e)}",
            }

    def _parse_fallback_response(
        self, content: str, original_title: str, original_content: str
    ) -> Dict:
        """å¤‡ç”¨å“åº”è§£ææ–¹æ³•"""
        try:
            # ç®€å•çš„æ–‡æœ¬è§£æä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
            lines = content.split("\n")
            translated_title = original_title
            translated_content = original_content
            analysis = content

            # å°è¯•æ‰¾åˆ°ç¿»è¯‘çš„æ ‡é¢˜å’Œå†…å®¹
            for i, line in enumerate(lines):
                line = line.strip()
                if "ç¿»è¯‘" in line and "æ ‡é¢˜" in line and ":" in line:
                    translated_title = line.split(":", 1)[1].strip()
                elif "ç¿»è¯‘" in line and "å†…å®¹" in line and ":" in line:
                    translated_content = line.split(":", 1)[1].strip()

            return {
                "translated_title": (
                    translated_title
                    if translated_title != original_title
                    else f"{original_title}ï¼ˆAIç¿»è¯‘ï¼‰"
                ),
                "translated_content": (
                    translated_content
                    if translated_content != original_content
                    else f"{original_content}ï¼ˆAIç¿»è¯‘ï¼‰"
                ),
                "analysis": analysis,
            }
        except Exception:
            return {
                "translated_title": f"{original_title}ï¼ˆè§£æå¤±è´¥ï¼‰",
                "translated_content": f"{original_content}ï¼ˆè§£æå¤±è´¥ï¼‰",
                "analysis": content,
            }

    def get_latest_version(self) -> Optional[Dict]:
        """è·å–æœ€æ–°ç‰ˆæœ¬ä¿¡æ¯"""
        results = self.collect()
        if results:
            return results[0]  # è¿”å›æœ€æ–°ç‰ˆæœ¬
        return None
