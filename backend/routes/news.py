from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from typing import List, Dict, Any
import logging
from datetime import datetime

from database import get_db
from models import NewsArticle, APICallRecord
from collectors.manager import CollectorManager
from collectors.ai_news_collector import AINewsCollector
from config import settings

router = APIRouter()
logger = logging.getLogger(__name__)

# åˆ›å»ºæ”¶é›†å™¨ç®¡ç†å™¨å®ä¾‹
collector_manager = CollectorManager()


@router.get("/")
async def get_news(db: Session = Depends(get_db)):
    """è·å–æ‰€æœ‰æ–°é—»"""
    try:
        news_articles = (
            db.query(NewsArticle)
            .order_by(NewsArticle.published_at.desc())
            .limit(50)
            .all()
        )

        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        news_list = []
        for article in news_articles:
            news_list.append(
                {
                    "id": article.id,
                    "title": article.title,
                    "summary": article.summary,
                    "content": article.content,
                    "url": article.url,
                    "source": article.source,
                    "author": article.author,
                    "published_at": (
                        article.published_at.isoformat()
                        if article.published_at
                        else None
                    ),
                    "created_at": (
                        article.created_at.isoformat() if article.created_at else None
                    ),
                    "tags": article.tags,
                    "model": article.model,
                }
            )

        return {"success": True, "data": news_list, "count": len(news_list)}
    except Exception as e:
        logger.error(f"è·å–æ–°é—»åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–æ–°é—»åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.get("/ai")
async def get_ai_news(db: Session = Depends(get_db)):
    """è·å–AIæ–°é—»"""
    try:
        ai_news = (
            db.query(NewsArticle)
            .filter(NewsArticle.source == "AIæ–°é—»åŠ©æ‰‹")
            .order_by(NewsArticle.published_at.desc())
            .limit(20)
            .all()
        )

        news_list = []
        for article in ai_news:
            news_list.append(
                {
                    "id": article.id,
                    "title": article.title,
                    "summary": article.summary,
                    "content": article.content,
                    "url": article.url,
                    "source": article.source,
                    "author": article.author,
                    "published_at": (
                        article.published_at.isoformat()
                        if article.published_at
                        else None
                    ),
                    "created_at": (
                        article.created_at.isoformat() if article.created_at else None
                    ),
                    "tags": article.tags,
                }
            )

        return {"success": True, "data": news_list, "count": len(news_list)}
    except Exception as e:
        logger.error(f"è·å–AIæ–°é—»å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–AIæ–°é—»å¤±è´¥: {str(e)}")


@router.post("/ai/collect")
async def collect_ai_news(db: Session = Depends(get_db)):
    """æ‰‹åŠ¨è§¦å‘AIæ–°é—»æ”¶é›† - æ¯æ—¥é™åˆ¶3æ¬¡"""
    try:
        # ğŸ”’ æ£€æŸ¥æ¯æ—¥è°ƒç”¨æ¬¡æ•°é™åˆ¶
        today = datetime.now().strftime("%Y-%m-%d")
        api_record = (
            db.query(APICallRecord)
            .filter(
                APICallRecord.api_name == APICallRecord.API_AI_NEWS_COLLECT,
                APICallRecord.call_date == today,
            )
            .first()
        )

        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æ¯æ—¥é™åˆ¶
        if api_record and api_record.call_count >= settings.daily_ai_collect_limit:
            raise HTTPException(
                status_code=429,
                detail=f"æ¯æ—¥AIæ–°é—»æ”¶é›†æ¬¡æ•°å·²è¾¾é™åˆ¶({settings.daily_ai_collect_limit}æ¬¡)ï¼Œä»Šæ—¥å·²è°ƒç”¨{api_record.call_count}æ¬¡ï¼Œè¯·æ˜å¤©å†è¯•",
            )

        # è·å–AIæ–°é—»æ”¶é›†å™¨
        ai_collector = collector_manager.get_collector("AIæ–°é—»æ”¶é›†å™¨")
        if not ai_collector:
            raise HTTPException(status_code=404, detail="AIæ–°é—»æ”¶é›†å™¨æœªæ‰¾åˆ°")

        # è¿è¡Œæ”¶é›†å™¨
        result = await ai_collector.run()

        if result["success"]:
            # ä¿å­˜æ–°é—»åˆ°æ•°æ®åº“
            items = result.get("items", [])
            saved_count = 0

            for item in items:
                try:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæ ‡é¢˜çš„æ–°é—»
                    existing = (
                        db.query(NewsArticle)
                        .filter(
                            NewsArticle.title == item.title,
                            NewsArticle.source == item.source,
                        )
                        .first()
                    )

                    if not existing:
                        news_article = NewsArticle(
                            title=item.title,
                            summary=item.summary,
                            content=item.content,
                            url=item.url,
                            source=item.source,
                            author=item.author,
                            published_at=item.published_at,
                            tags=item.tags,
                            model=item.model,
                        )
                        db.add(news_article)
                        saved_count += 1

                except Exception as e:
                    logger.error(f"ä¿å­˜æ–°é—»é¡¹å¤±è´¥: {str(e)}")
                    continue

            db.commit()

            # ğŸ”’ æ›´æ–°APIè°ƒç”¨è®°å½•
            if api_record:
                api_record.call_count += 1
                api_record.last_call_time = datetime.now()
                api_record.updated_at = datetime.now()
            else:
                # åˆ›å»ºæ–°çš„è°ƒç”¨è®°å½•
                api_record = APICallRecord(
                    api_name=APICallRecord.API_AI_NEWS_COLLECT,
                    call_date=today,
                    call_count=1,
                    last_call_time=datetime.now(),
                )
                db.add(api_record)

            db.commit()

            return {
                "success": True,
                "message": f"æˆåŠŸæ”¶é›†å¹¶ä¿å­˜ {saved_count} æ¡AIæ–°é—»",
                "collected_count": result["count"],
                "saved_count": saved_count,
                "execution_time": result["execution_time"],
                "remaining_calls": settings.daily_ai_collect_limit
                - api_record.call_count,  # ğŸ”’ è¿”å›å‰©ä½™è°ƒç”¨æ¬¡æ•°
            }
        else:
            return {
                "success": False,
                "error": result.get("error", "æ”¶é›†å¤±è´¥"),
                "execution_time": result.get("execution_time", 0),
            }

    except Exception as e:
        logger.error(f"AIæ–°é—»æ”¶é›†å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"AIæ–°é—»æ”¶é›†å¤±è´¥: {str(e)}")


@router.get("/ai/status")
async def get_ai_collect_status(db: Session = Depends(get_db)):
    """è·å–AIæ–°é—»æ”¶é›†çŠ¶æ€å’Œå‰©ä½™æ¬¡æ•°"""
    try:
        today = datetime.now().strftime("%Y-%m-%d")
        api_record = (
            db.query(APICallRecord)
            .filter(
                APICallRecord.api_name == APICallRecord.API_AI_NEWS_COLLECT,
                APICallRecord.call_date == today,
            )
            .first()
        )

        current_calls = api_record.call_count if api_record else 0
        remaining_calls = max(0, settings.daily_ai_collect_limit - current_calls)

        return {
            "success": True,
            "data": {
                "current_calls": current_calls,
                "remaining_calls": remaining_calls,
                "max_calls": settings.daily_ai_collect_limit,
                "can_collect": remaining_calls > 0,
                "current_model": settings.ai_model,  # è¿”å›å½“å‰ä½¿ç”¨çš„æ¨¡å‹
                "last_call_time": (
                    api_record.last_call_time.isoformat() if api_record else None
                ),
            },
        }
    except Exception as e:
        logger.error(f"è·å–AIæ”¶é›†çŠ¶æ€å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–AIæ”¶é›†çŠ¶æ€å¤±è´¥: {str(e)}")


@router.get("/{news_id}")
async def get_news_detail(news_id: int, db: Session = Depends(get_db)):
    """è·å–æ–°é—»è¯¦æƒ…"""
    try:
        news_article = db.query(NewsArticle).filter(NewsArticle.id == news_id).first()

        if not news_article:
            raise HTTPException(status_code=404, detail="æ–°é—»ä¸å­˜åœ¨")

        return {
            "success": True,
            "data": {
                "id": news_article.id,
                "title": news_article.title,
                "summary": news_article.summary,
                "content": news_article.content,
                "url": news_article.url,
                "source": news_article.source,
                "author": news_article.author,
                "published_at": (
                    news_article.published_at.isoformat()
                    if news_article.published_at
                    else None
                ),
                "created_at": (
                    news_article.created_at.isoformat()
                    if news_article.created_at
                    else None
                ),
                "tags": news_article.tags,
            },
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æ–°é—»è¯¦æƒ…å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–æ–°é—»è¯¦æƒ…å¤±è´¥: {str(e)}")


@router.get("/sources/list")
async def get_news_sources(db: Session = Depends(get_db)):
    """è·å–æ–°é—»æ¥æºåˆ—è¡¨"""
    try:
        sources = db.query(NewsArticle.source).distinct().all()
        source_list = [source[0] for source in sources if source[0]]

        return {"success": True, "data": source_list, "count": len(source_list)}
    except Exception as e:
        logger.error(f"è·å–æ–°é—»æ¥æºå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–æ–°é—»æ¥æºå¤±è´¥: {str(e)}")


@router.get("/sources/{source_name}")
async def get_news_by_source(source_name: str, db: Session = Depends(get_db)):
    """æ ¹æ®æ¥æºè·å–æ–°é—»"""
    try:
        news_articles = (
            db.query(NewsArticle)
            .filter(NewsArticle.source == source_name)
            .order_by(NewsArticle.published_at.desc())
            .limit(30)
            .all()
        )

        news_list = []
        for article in news_articles:
            news_list.append(
                {
                    "id": article.id,
                    "title": article.title,
                    "summary": article.summary,
                    "content": article.content,
                    "url": article.url,
                    "source": article.source,
                    "author": article.author,
                    "published_at": (
                        article.published_at.isoformat()
                        if article.published_at
                        else None
                    ),
                    "created_at": (
                        article.created_at.isoformat() if article.created_at else None
                    ),
                    "tags": article.tags,
                }
            )

        return {
            "success": True,
            "data": news_list,
            "count": len(news_list),
            "source": source_name,
        }
    except Exception as e:
        logger.error(f"è·å–æ¥æºæ–°é—»å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–æ¥æºæ–°é—»å¤±è´¥: {str(e)}")
